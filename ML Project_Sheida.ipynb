{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'realtordata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5df5352f434b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#read the csv file into a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mreal_state_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"realtordata.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mincome\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Income.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"population.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'realtordata.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#read the csv file into a dataframe\n",
    "real_state_data = pd.read_csv(\"realtordata.csv\")\n",
    "income = pd.read_csv(\"Income.csv\")\n",
    "population = pd.read_csv(\"population.csv\")\n",
    "land = pd.read_csv(\"land.csv\")\n",
    "st_abr = pd.read_csv(\"state_abr.csv\")\n",
    "geo_data= pd.read_csv(\"geo-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_state_data = pd.read_csv(\"realtordata.csv\")\n",
    "geo_data= pd.read_csv(\"geo-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_state_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_state_data=pd.DataFrame (real_state_data , columns =['price','zip_code', 'bed', 'bath', 'acre_lot','house_size'])\n",
    "real_state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_state_data=real_state_data.dropna(axis=0)\n",
    "real_state_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_state_data['zip_code'] = real_state_data['zip_code'].astype(int)\n",
    "real_state_data['zip_code'] = real_state_data['zip_code'].astype(str)\n",
    "geo_data['zipcode']=geo_data['zipcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_state_data['zip_code']=real_state_data['zip_code'].apply(lambda x: x.zfill(5))\n",
    "real_state_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame (real_state_data , columns = ['zip_code', 'price', 'house_size' ])\n",
    "realstate_grouped = df1.groupby(['zip_code'],as_index=False).mean()\n",
    "realstate_grouped['price_per_sqft']=realstate_grouped['price']/realstate_grouped['house_size']\n",
    "realstate_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = realstate_grouped[['price_per_sqft']].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "n_clusters=3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "\n",
    "kmeans.fit(X_std)\n",
    "\n",
    "labels = kmeans.predict(X_std)\n",
    "\n",
    "for n, i in enumerate(labels):\n",
    "    if i==0:\n",
    "        realstate_grouped.loc[n,'Cluster']=i+1\n",
    "    elif i==1:\n",
    "        realstate_grouped.loc[n,'Cluster']=i+2\n",
    "    elif i==2:\n",
    "        realstate_grouped.loc[n,'Cluster']=i\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Visualize clusters\n",
    "colors = ['red', 'green', 'blue']\n",
    "plt.scatter(realstate_grouped.index,X_std[:,0], c=labels)\n",
    "plt.ylabel('Average House Price (standardized)')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(X[labels==0], label='Cluster 1')\n",
    "plt.hist(X[labels==2], label='Cluster 2')\n",
    "plt.hist(X[labels==1],label='Cluster 3')\n",
    "plt.xlabel('Average House Price')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " realstate_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realstate_grouped=realstate_grouped.loc[:,['zip_code','Cluster']]\n",
    "realstate_clustered=real_state_data.merge(realstate_grouped, how='inner', on=['zip_code'])\n",
    "realstate_clustered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "realstate_clustered.rename(columns = {'zip_code':'zipcode'}, inplace = True)\n",
    "real_state_bycounty=realstate_clustered.merge(geo_data, how='inner', on='zipcode')\n",
    "real_state=real_state_bycounty.drop(['state_fips','state','city'],axis=1)\n",
    "real_state.rename(columns = {'state_abbr':'State'}, inplace = True)\n",
    "real_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_state.rename(columns = {'county':'County'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income=pd.DataFrame (income , columns =['State','County','PerCapitaInc'])\n",
    "income=income.dropna(axis=0)\n",
    "income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realstate_income=real_state.merge(income, how='inner', on=['State','County'])\n",
    "realstate_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame (land , columns = ['USPS','NAME', 'ALAND' ])\n",
    "df3.rename(columns = {'USPS':'State'}, inplace = True)\n",
    "df3.rename(columns = {'NAME':'County'}, inplace = True)\n",
    "df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for c in df3.County:\n",
    "    Cnt=c.split(' County')[0]\n",
    "    df3.loc[i,'County']=Cnt\n",
    "    i+=1\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realstate_income_land=realstate_income.merge(df3, how='inner', on=['State','County'])\n",
    "realstate_income_land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame (population , columns = ['State', 'CountyName', 'TotalPop' ])\n",
    "df4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df4.merge(st_abr, how='inner', on='State')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for c in df4.CountyName:\n",
    "    Cnt=c.split(' County')[0]\n",
    "    df4.loc[i,'CountyName']=Cnt\n",
    "    i+=1\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population=df4.drop(['State'], axis=1)\n",
    "population.rename(columns = {'CountyName':'County'}, inplace = True)\n",
    "population.rename(columns = {'Postal':'State'}, inplace = True)\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "realstate_income_land_population=realstate_income_land.merge(population, how='inner', on=['State', 'County'])\n",
    "realstate_income_land_population['Price_perft2']=realstate_income_land_population['price']/realstate_income_land_population['house_size']\n",
    "realstate_income_land_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "dfnn=realstate_income_land_population.copy()\n",
    "def remove_outliers_zscore(df_column):\n",
    "    z_scores = stats.zscore(df_column)\n",
    "    abs_z_scores = abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 3)\n",
    "    return df_column[filtered_entries]\n",
    "\n",
    "realstate_income_land_population[['bed', 'bath','acre_lot','house_size','Price_perft2']] = realstate_income_land_population[['bed', 'bath','acre_lot','house_size','Price_perft2']].apply(remove_outliers_zscore)\n",
    "\n",
    "realstate_income_land_population=realstate_income_land_population.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "correlation = realstate_income_land_population.drop(columns=['Cluster','Price_perft2']).corr()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(correlation,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "abs(correlation['price']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realstate_income_land_population['size_bin'] = pd.cut(realstate_income_land_population['house_size'], bins=10)\n",
    "\n",
    "grouped_data = realstate_income_land_population.groupby(['Cluster', 'size_bin'])['price'].mean().reset_index()\n",
    "\n",
    "pivot_data = grouped_data.pivot(index='size_bin', columns='Cluster', values='price')\n",
    "\n",
    "\n",
    "ax=pivot_data.plot(kind='bar')\n",
    "plt.xlabel('House Size Bins')\n",
    "plt.ylabel('Average Price')\n",
    "ax.legend(labels=['Cluster 1', 'Cluster 2', 'Cluster 3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = realstate_income_land_population.groupby(['Cluster','bath']).mean().reset_index()\n",
    "fig, ax = plt.subplots()\n",
    "colors = ['red', 'green', 'blue']\n",
    "for i, c in enumerate([1, 2, 3]):\n",
    "    subset = grouped[grouped['Cluster'] == c]\n",
    "    ax.scatter(subset['bath'], subset['price'], color=colors[i], label=f'Cluster {c}')\n",
    "    plt.xlabel(\"Number of Baths\")\n",
    "    plt.ylabel(\"Mean Price\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = realstate_income_land_population.groupby(['Cluster','bed']).mean().reset_index()\n",
    "fig, ax = plt.subplots()\n",
    "colors = ['red', 'green', 'blue']\n",
    "for i, c in enumerate([1, 2, 3]):\n",
    "    subset = grouped[grouped['Cluster'] == c]\n",
    "    ax.scatter(subset['bed'], subset['price'], color=colors[i], label=f'Cluster {c}')\n",
    "    plt.xlabel(\"Number of Bedrooms\")\n",
    "    plt.ylabel(\"Mean Price\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realstate_income_land_population['acre_bin'] = pd.cut(realstate_income_land_population['acre_lot'], bins=10)\n",
    "\n",
    "grouped_data = realstate_income_land_population.groupby(['Cluster', 'acre_bin'])['price'].mean().reset_index()\n",
    "\n",
    "pivot_data = grouped_data.pivot(index='acre_bin', columns='Cluster', values='price')\n",
    "\n",
    "\n",
    "ax=pivot_data.plot(kind='bar')\n",
    "plt.xlabel('Acre Bins')\n",
    "plt.ylabel('Average Price')\n",
    "ax.legend(labels=['Cluster 1', 'Cluster 2', 'Cluster 3'])\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final_data=pd.DataFrame (realstate_income_land_population , columns =['price', 'bed', 'bath', 'acre_lot','house_size', 'Cluster', 'PerCapitaInc', 'ALAND', 'TotalPop'])\n",
    "Final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1:\n",
      "   Validation Mean R2 Linear Regression = 0.546\n",
      "   Validation Mean R2 Random Forest = 0.982\n",
      "Cluster 2:\n",
      "   Validation Mean R2 Linear Regression = 0.671\n",
      "   Validation Mean R2 Random Forest = 0.981\n",
      "Cluster 3:\n",
      "   Validation Mean R2 Linear Regression = 0.890\n",
      "   Validation Mean R2 Random Forest = 0.983\n",
      "\n",
      "\n",
      "Test Mean R2 Linear Regression = 0.697\n",
      "Test Mean R2 Random Forest = 0.982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# number of folds\n",
    "k = 4\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=10)\n",
    "\n",
    "r2_linreg_test_list = []\n",
    "r2_rf_test_list = []\n",
    "#r2_svm_test_list = []\n",
    "\n",
    "for cluster in range(1, n_clusters+1):\n",
    "    \n",
    "    \n",
    "    X_cluster = Final_data[Final_data['Cluster'] == cluster].drop(['Cluster','price'], axis=1)\n",
    "    y_cluster = Final_data[Final_data['Cluster'] == cluster]['price']\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X_cluster, y_cluster, test_size=0.2, random_state=10)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    r2_linreg_list = []\n",
    "    r2_rf_list = []\n",
    "    #r2_svm_list = []\n",
    "    \n",
    "    # Loop through each fold\n",
    "    for train_idx, val_idx in kf.split(X_train_val):\n",
    "        \n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_val = X_train_val.iloc[train_idx], X_train_val.iloc[val_idx]\n",
    "        y_train, y_val = y_train_val.iloc[train_idx], y_train_val.iloc[val_idx]\n",
    "        \n",
    "        # Scale the features \n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        \n",
    "        # Fit a linear regression model to the data\n",
    "        linreg_model = LinearRegression()\n",
    "        linreg_model.fit(X_train_scaled, y_train)\n",
    "        y_linreg_pred = linreg_model.predict(X_val_scaled)\n",
    "        \n",
    "        # Fit a random forest model to the data\n",
    "        rf_model = RandomForestRegressor(n_estimators=100, random_state=10)\n",
    "        rf_model.fit(X_train_scaled, y_train)\n",
    "        y_rf_pred = rf_model.predict(X_val_scaled)\n",
    "        \n",
    "        # Fit a SVM model to the data\n",
    "        #svm_model = SVR(kernel='linear')\n",
    "        #svm_model.fit(X_train_scaled, y_train)\n",
    "        #y_svm_pred = svm_model.predict(X_val_scaled)\n",
    "        \n",
    "        # Calculate R2 for each model and append to the respective list\n",
    "        r2_linreg_list.append(r2_score(y_val, y_linreg_pred))\n",
    "        r2_rf_list.append(r2_score(y_val, y_rf_pred))\n",
    "        #r2_svm_list.append(r2_score(y_val, y_svm_pred))\n",
    "    \n",
    "    #Prediction of the test set\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    y_linreg_test_pred = linreg_model.predict(X_test_scaled)\n",
    "    r2_linreg_test_list.append(r2_score(y_test, y_linreg_test_pred))\n",
    "    \n",
    "    y_rf_test_pred = rf_model.predict(X_test_scaled)\n",
    "    r2_rf_test_list.append(r2_score(y_test, y_rf_test_pred))\n",
    "    \n",
    "    #y_svm_test_pred = svm_model.predict(X_test_scaled)\n",
    "    #r2_svm_test_list.append(r2_score(y_test, y_svm_test_pred))\n",
    "    \n",
    "    \n",
    "    # Print the mean R2 for validation set\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    print(f\"   Validation Mean R2 Linear Regression = {sum(r2_linreg_list)/k:.3f}\")\n",
    "    print(f\"   Validation Mean R2 Random Forest = {sum(r2_rf_list)/k:.3f}\")\n",
    "    #print(f\"  Validation Mean R2 SVM = {sum(r2_svm_list)/k:.3f}\")\n",
    "    \n",
    "    \n",
    "# Print the mean R2 for test set\n",
    "print('\\n')\n",
    "print(f\"Test Mean R2 Linear Regression = {sum(r2_linreg_test_list)/n_clusters:.3f}\")\n",
    "print(f\"Test Mean R2 Random Forest = {sum(r2_rf_test_list)/n_clusters:.3f}\")\n",
    "#print(f\"Test Mean R2 SVM = {sum(r2_svm_test_list)/n_clusters:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: 5 principal components explain 90% of the variance\n",
      "   Validation Mean R2 Linear Regression = 0.497\n",
      "   Validation Mean R2 Random Forest = 0.978\n",
      "Cluster 2: 5 principal components explain 90% of the variance\n",
      "   Validation Mean R2 Linear Regression = 0.655\n",
      "   Validation Mean R2 Random Forest = 0.979\n",
      "Cluster 3: 4 principal components explain 90% of the variance\n",
      "   Validation Mean R2 Linear Regression = 0.875\n",
      "   Validation Mean R2 Random Forest = 0.956\n",
      "\n",
      "\n",
      "Test Mean R2 Linear Regression = 0.671\n",
      "Test Mean R2 Random Forest = 0.949\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# number of folds\n",
    "k = 4\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=10)\n",
    "\n",
    "r2_linreg_test_list = []\n",
    "r2_rf_test_list = []\n",
    "#r2_svm_test_list = []\n",
    "\n",
    "\n",
    "for cluster in range(1, n_clusters+1):\n",
    "    \n",
    "    \n",
    "    X_cluster = Final_data[Final_data['Cluster'] == cluster].drop(['Cluster','price'], axis=1)\n",
    "    y_cluster = Final_data[Final_data['Cluster'] == cluster]['price']\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X_cluster, y_cluster, test_size=0.2, random_state=10)\n",
    "    \n",
    "    X_train_val_scaled = scaler.fit_transform(X_train_val)\n",
    "    \n",
    "    #Use PCA to reduce the number of features\n",
    "    pca = PCA()\n",
    "    X_train_val_pca = pca.fit_transform(X_train_val_scaled)\n",
    "    \n",
    "    variance_ratio = pca.explained_variance_ratio_\n",
    "    n_components = 0\n",
    "    explained_variance = 0\n",
    "    for i in range(len(variance_ratio)):\n",
    "        explained_variance += variance_ratio[i]\n",
    "        n_components += 1\n",
    "        if explained_variance >= 0.9:\n",
    "            break\n",
    "    print(f\"Cluster {cluster}: {n_components} principal components explain 90% of the variance\")\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_val_pca = pca.fit_transform(X_train_val)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    \n",
    "    # Evaluation metrics\n",
    "    r2_linreg_list = []\n",
    "    r2_rf_list = []\n",
    "    #r2_svm_list = []\n",
    "    \n",
    "    # Loop through each fold\n",
    "    for train_idx, val_idx in kf.split(X_train_val_pca):\n",
    "        \n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_val = X_train_val_pca[train_idx], X_train_val_pca[val_idx]\n",
    "        y_train, y_val = y_train_val.iloc[train_idx], y_train_val.iloc[val_idx]\n",
    "        \n",
    "        # Scale the features \n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        \n",
    "        # Fit a linear regression model to the data\n",
    "        linreg_model = LinearRegression()\n",
    "        linreg_model.fit(X_train_scaled, y_train)\n",
    "        y_linreg_pred = linreg_model.predict(X_val_scaled)\n",
    "        \n",
    "        # Fit a random forest model to the data\n",
    "        rf_model = RandomForestRegressor(n_estimators=100, random_state=10)\n",
    "        rf_model.fit(X_train_scaled, y_train)\n",
    "        y_rf_pred = rf_model.predict(X_val_scaled)\n",
    "        \n",
    "        # Fit a SVM model to the data\n",
    "        #svm_model = SVR(kernel='linear')\n",
    "        #svm_model.fit(X_train_scaled, y_train)\n",
    "        #y_svm_pred = svm_model.predict(X_val_scaled)\n",
    "        \n",
    "        # Calculate R2 for each model and append to the respective list\n",
    "        r2_linreg_list.append(r2_score(y_val, y_linreg_pred))\n",
    "        r2_rf_list.append(r2_score(y_val, y_rf_pred))\n",
    "        #r2_svm_list.append(r2_score(y_val, y_svm_pred))\n",
    "    \n",
    "    #Prediction of the test set\n",
    "    X_test_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    y_linreg_test_pred = linreg_model.predict(X_test_scaled)\n",
    "    r2_linreg_test_list.append(r2_score(y_test, y_linreg_test_pred))\n",
    "    \n",
    "    y_rf_test_pred = rf_model.predict(X_test_scaled)\n",
    "    r2_rf_test_list.append(r2_score(y_test, y_rf_test_pred))\n",
    "    \n",
    "    #y_svm_test_pred = svm_model.predict(X_test_scaled)\n",
    "    #r2_svm_test_list.append(r2_score(y_test, y_svm_test_pred))\n",
    "    \n",
    "    \n",
    "    # Print the mean R2 for validation set\n",
    "    print(f\"   Validation Mean R2 Linear Regression = {sum(r2_linreg_list)/k:.3f}\")\n",
    "    print(f\"   Validation Mean R2 Random Forest = {sum(r2_rf_list)/k:.3f}\")\n",
    "    #print(f\"  Validation Mean R2 SVM = {sum(r2_svm_list)/k:.3f}\")\n",
    "    \n",
    "    \n",
    "# Print the mean R2 for test set\n",
    "print('\\n')\n",
    "print(f\"Test Mean R2 Linear Regression = {sum(r2_linreg_test_list)/n_clusters:.3f}\")\n",
    "print(f\"Test Mean R2 Random Forest = {sum(r2_rf_test_list)/n_clusters:.3f}\")\n",
    "#print(f\"Test Mean R2 SVM = {sum(r2_svm_test_list)/n_clusters:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "adfa0e167eefde950ae61b016121cb4512e3f386db0fe40047a51ac2dfe35bf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
